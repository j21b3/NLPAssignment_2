{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 2.Tagging\n",
    "#### 2.1 LSTM Tagging\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./Mydata.json\",'r+') as f:\n",
    "    dataset = json.load(f)\n",
    "tmp = {}\n",
    "for key in dataset['id2label']:\n",
    "    tmp[int(key)] = dataset['id2label'][key]\n",
    "dataset['id2label'] = tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,\n",
    "                 vocalsize, tagsize, embedding_size,dropout_rate, device,batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocalsize = vocalsize\n",
    "        self.tagsize = tagsize\n",
    "        self.embedding_size = embedding_size\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # self.word_embeddings = nn.Embedding(self.vocalsize, self.input_size)\n",
    "        self.encoder = nn.Embedding(self.vocalsize, self.embedding_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=1,bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.output = nn.Linear(self.hidden_size*2, self.tagsize)\n",
    "\n",
    "        # self.hidden = (torch.zeros(1,2,self.hidden_size).to(self.device))\n",
    "        # self.hidden = (torch.zeros(2, self.input_size, self.hidden_size).to(self.device),\n",
    "        #        torch.zeros(2, self.input_size, self.hidden_size).to(self.device))\n",
    "        self.init_hidden()\n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # embed = self.word_embeddings(sentence)\n",
    "        # vie = embed.view(len(sentence), self.input_size)\n",
    "        # print(vie.shape)\n",
    "        # print(\"print sentence\",sentence)\n",
    "        emb = self.encoder(sentence)\n",
    "        # print(\"print inside model\",emb,emb.shape)\n",
    "        # input()\n",
    "        lstm_out, self.hidden = self.lstm(emb, self.hidden)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # tag_space = self.output()\n",
    "        # tag_score = F.log_softmax(tag_space, dim=self.tagsize)\n",
    "        return self.output(lstm_out[:,-1,:])\n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.hidden = (torch.zeros(2, self.batch_size, self.hidden_size).to(self.device),\n",
    "               torch.zeros(2, self.batch_size, self.hidden_size).to(self.device))\n",
    "        # self.hidden = torch.zeros(1,batch_size,self.hidden_size).to(self.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag torch.Size([9, 9]) tensor([[-0.0105,  0.2042,  0.2424, -0.0508, -0.1067, -0.1870, -0.0094,  0.0432,\n",
      "         -0.0840],\n",
      "        [ 0.0182,  0.2412,  0.1532,  0.0083, -0.1052, -0.2246, -0.0359,  0.0897,\n",
      "         -0.0566],\n",
      "        [ 0.1849,  0.2124,  0.2276,  0.0564, -0.1667, -0.2076, -0.0007,  0.1814,\n",
      "         -0.1019],\n",
      "        [ 0.1181,  0.1515,  0.1312,  0.0571, -0.3071, -0.3442, -0.0017,  0.0335,\n",
      "          0.0189],\n",
      "        [ 0.1016,  0.0997,  0.3062,  0.0947, -0.1751, -0.2933,  0.0118,  0.1315,\n",
      "          0.0703],\n",
      "        [ 0.1784,  0.0926,  0.0322, -0.0983, -0.1461, -0.1632, -0.0787,  0.1553,\n",
      "         -0.0710],\n",
      "        [ 0.2158,  0.0986,  0.1772, -0.0522, -0.1486, -0.1683, -0.0894,  0.1734,\n",
      "         -0.0932],\n",
      "        [-0.0256,  0.0786,  0.1555, -0.0581, -0.2717, -0.2627, -0.0225,  0.0527,\n",
      "          0.1744],\n",
      "        [-0.0694,  0.0906,  0.2280, -0.1733, -0.1201, -0.1895,  0.0006,  0.0229,\n",
      "          0.0120]])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device='cpu'\n",
    "model = MyLSTM(input_size=1, embedding_size=10, hidden_size=10,\n",
    "               vocalsize=len(dataset['word2id']),\n",
    "               tagsize=len(dataset['label2id'])-1,\n",
    "               dropout_rate=0.1,\n",
    "               device=device,\n",
    "               batch_size=1)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # inp = torch.tensor(np.matrix(dataset['trainset']['data'][0]).T, dtype=torch.long).unsqueeze(0)\n",
    "    # inp = torch.tensor(np.matrix(dataset['trainset']['data'][0]).T[0],dtype=torch.long)\n",
    "    sen = dataset['trainset']['data'][0]\n",
    "    sen = [dataset['word2id'][w] for w in sen]\n",
    "    model.init_hidden()\n",
    "    # print(idx)\n",
    "    inp = torch.tensor(np.matrix(sen).T,\n",
    "                       dtype = torch.long).to(device)\n",
    "    # print(inp)\n",
    "    # hidden = model.init_hidden(126)\n",
    "    tag_scores = model(inp)\n",
    "    print(\"tag\",tag_scores.shape,tag_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def id2Label(labels,id2label:dict):\n",
    "    retlabel = []\n",
    "    for seq in labels:\n",
    "        tmp = [id2label[each] for each in seq]\n",
    "        retlabel.append(tmp[:])\n",
    "    return retlabel\n",
    "\n",
    "def id2Label_RemoveSpecialToken(labels,id2label:dict):\n",
    "    retlabel = []\n",
    "    pad = len(id2label)\n",
    "    for idx,seq in enumerate(labels):\n",
    "        tmp = []\n",
    "        for each in seq:\n",
    "            if each == pad:\n",
    "                break\n",
    "            tmp.append(id2label[each])\n",
    "        retlabel.append(tmp[:])\n",
    "    return retlabel\n",
    "\n",
    "def label2ID(labels,label2id):\n",
    "    return [label2id[each] for each in labels]\n",
    "\n",
    "def sen2ID(sentence,word2id):\n",
    "    return [word2id[w] for w in sentence]\n",
    "\n",
    "# def get_batch(source,label,idx,batch_size):\n",
    "#     dataset = source[idx*batch_size:idx*batch_size+batch_size]\n",
    "#     labels = label[idx*batch_size:idx*batch_size+batch_size]\n",
    "#     maxlen = max([getSeqLen(each) for each in dataset])\n",
    "#     batchdata = []\n",
    "#     for each in dataset:\n",
    "#         batchdata.append(each[0][:maxlen])\n",
    "#     label = [la[:maxlen] for la in labels]\n",
    "#     return batchdata,label,maxlen\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----End Epoch  0 loss: 6.082562439301473 -----\n",
      "find a better model, model saved as ./LSTModle/EPOCH0_6.082562439301473_Mon_Nov__7_19_56_21_2022.pt\n",
      "-----Test model on  0 -----\n",
      "-----Output classification report:-----\n",
      "ACC: 0.8674275869494993  F1: 0.3992332968236583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.60      0.62      0.61      1668\n",
      "        MISC       0.37      0.30      0.33       702\n",
      "         ORG       0.38      0.22      0.28      1661\n",
      "         PER       0.28      0.36      0.32      1617\n",
      "\n",
      "   micro avg       0.41      0.39      0.40      5648\n",
      "   macro avg       0.41      0.37      0.38      5648\n",
      "weighted avg       0.41      0.39      0.39      5648\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-c6ea8a5db3aa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtag_scores\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msen_truetag\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[1;31m# loss = 0.0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mepoch_loss\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mtag_scores\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Python\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Python\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    154\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 156\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "batch_size = 1\n",
    "EPOCH = 10\n",
    "learning_rate = 0.3\n",
    "testFreq = 1\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device='cpu'\n",
    "torch.manual_seed(100)\n",
    "traindata = dataset['trainset']['data']\n",
    "# trainlabel = dataset['trainset']['label']\n",
    "trainlabel = dataset['trainset']['label']\n",
    "\n",
    "testdata = dataset['testset']['data']\n",
    "# testlabel = dataset['testset']['label']\n",
    "testlabel = dataset['testset']['label']\n",
    "# testLabelWord = label2ID(testlabel,dataset['label2id'])\n",
    "# testLabelWordnoSpe = id2Label_RemoveSpecialToken(testlabel,dataset['id2label'])\n",
    "\n",
    "model = MyLSTM(input_size=1, embedding_size=64, hidden_size=64,\n",
    "               vocalsize=len(dataset['word2id']),\n",
    "               tagsize=len(dataset['label2id'])-1,      # remove PAD\n",
    "               # tagsize=len(dataset['label2id']),\n",
    "               dropout_rate=0.1,\n",
    "               device=device,\n",
    "               batch_size=batch_size).to(device)\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "minloss = float('inf')\n",
    "# BestModel = None\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # tag_sc = np.array([])\n",
    "    epoch_loss = 0.0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for idx,sentence in enumerate(traindata):\n",
    "    # for _, i in enumerate(range(0,len(traindata)-1,batch_size)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "\n",
    "        # sen_tag = []\n",
    "\n",
    "        sen_truetag = label2ID(trainlabel[idx],dataset['label2id'])\n",
    "        # print(\"sen_shape:\",sen_truetag.shape)\n",
    "        # for word in np.matrix(sentence).T:\n",
    "        # sentence,sen_truetag,seqlen = get_batch(traindata,dataset['trainset']['label'],i,batch_size)\n",
    "        model.init_hidden()\n",
    "        inp = torch.tensor(np.matrix(sen2ID(traindata[idx],dataset['word2id'])).T,dtype=torch.long).to(device)\n",
    "        # inp = torch.tensor(np.matrix(sentence),dtype=torch.long).to(device)\n",
    "        # print(\"inp:\",inp.shape)\n",
    "        tag_scores = model(inp)\n",
    "        sen_truetag = torch.tensor(sen_truetag,dtype=torch.long).to(device)\n",
    "        loss = criterion(tag_scores,sen_truetag)\n",
    "        # loss = 0.0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss+=tag_scores.shape[0]*loss.item()\n",
    "    # print(true_tags.shape)\n",
    "    # print(tag_sc.shape)\n",
    "    # true_tags = torch.tensor(trainlabel,dtype=torch.long).to(device)\n",
    "    # tag_sc = torch.tensor(np.array(tag_sc),dtype=torch.long).to(device)\n",
    "\n",
    "    # print(loss.real)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    aveloss = epoch_loss/len(traindata)\n",
    "    print(\"-----End Epoch \",epoch,\"loss:\",aveloss,\"-----\")\n",
    "    if aveloss<minloss:\n",
    "        minloss = aveloss\n",
    "        torch.save(model,f\"./LSTModle/EPOCH{epoch}_{aveloss}_{datetime.now().ctime().replace(' ','_').replace(':','_')}.pt\")\n",
    "        print(f\"find a better model, model saved as ./LSTModle/EPOCH{epoch}_{aveloss}_{datetime.now().ctime().replace(' ','_').replace(':','_')}.pt\")\n",
    "\n",
    "    if (epoch+1)%testFreq==0:\n",
    "        # test the model\n",
    "        print(\"-----Test model on \",epoch,'-----')\n",
    "        predict = []\n",
    "        optimizer.zero_grad()\n",
    "        for idx,sentence in enumerate(testdata):\n",
    "            model.init_hidden()\n",
    "            # sen_tag = []\n",
    "            sen_truetag = torch.tensor(label2ID(testlabel[idx],dataset['label2id']),\n",
    "                                       dtype=torch.long).to(device)\n",
    "            # for word in np.matrix(sentence).T:\n",
    "            inp = torch.tensor(np.matrix(sen2ID(testdata[idx],dataset['word2id'])).T,\n",
    "                               dtype=torch.long).to(device)\n",
    "            # print(\"inp:\",idx)\n",
    "            tag_scores = model(inp)\n",
    "            thispredict = torch.max(tag_scores.data,1).indices.cpu()\n",
    "            # print(thispredict.shape)\n",
    "            predict.append(list(thispredict.numpy()))\n",
    "\n",
    "        print(\"-----Output classification report:-----\")\n",
    "        predict = id2Label(predict,dataset['id2label'])\n",
    "        print(\"ACC:\",accuracy_score(testlabel,predict),\" F1:\",f1_score(testlabel,predict,zero_division=1))\n",
    "        print(classification_report(testlabel,predict))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Transformer Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# device='cpu'\n",
    "# model2 = MyLSTM(input_size=2, embedding_size=10, hidden_size=10,\n",
    "#                vocalsize=len(dataset['word2id']),\n",
    "#                tagsize=len(dataset['label2id']),\n",
    "#                device=device).to(device)\n",
    "# errdata  = dataset['testset']['data'][3451]\n",
    "# errlabel = dataset['testset']['label'][3451]\n",
    "# print(len(errdata[0]),len(errdata[1]))\n",
    "# print(errlabel)\n",
    "# print(errdata[0],errdata[1])\n",
    "# # ... 3 2 3 3 3....???\n",
    "#\n",
    "# # model2.init_hidden(2)\n",
    "# sen_truetag = torch.tensor(errlabel,dtype=torch.long).to(device)\n",
    "#\n",
    "# inp = torch.tensor(np.matrix(errdata).T,dtype=torch.long).to(device)\n",
    "# print(inp.shape)\n",
    "# tag_scores = model2(inp)\n",
    "# predict = torch.max(tag_scores.data,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
